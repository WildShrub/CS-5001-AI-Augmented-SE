{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e104d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ecf06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install litellm --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import json\n",
    "import strands, strands_tools\n",
    "\n",
    "MODEL = \"ollama/devstral-small-2:24b-cloud\"   # change to the model you have pulled in Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89666800-3c37-4eb6-a93a-b6355ab224ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful agents that explains things in simple language\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's recursion?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ee41fc-3772-4821-9b98-aa0f1aaf6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(model=MODEL, messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65013f8e-bf04-4ae7-bbca-1e0de23e189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursion is a way of solving a problem by breaking it down into smaller, similar problems. It's like a loop that calls itself to solve a smaller version of the same problem until it reaches a simple case that can be solved directly.\n",
      "\n",
      "### Simple Example:\n",
      "Imagine you have a stack of plates, and you want to take them all off. You can do it by:\n",
      "1. Taking the top plate off.\n",
      "2. Then, you have a smaller stack (without the top plate).\n",
      "3. Repeat the same process (taking the top plate off) until no plates are left.\n",
      "\n",
      "This is recursion! The \"smaller stack\" is the smaller version of the original problem.\n",
      "\n",
      "### Key Parts of Recursion:\n",
      "1. **Base Case**: The simplest case that stops the recursion (e.g., no plates left).\n",
      "2. **Recursive Case**: The problem calls itself with a smaller input (e.g., taking one plate off).\n",
      "\n",
      "### Why Use Recursion?\n",
      "- It makes some problems easier to understand (like tree structures or divide-and-conquer problems).\n",
      "- It can be elegant and concise.\n",
      "\n",
      "### Example in Code (Factorial):\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n == 0:  # Base case\n",
      "        return 1\n",
      "    else:       # Recursive case\n",
      "        return n * factorial(n - 1)\n",
      "```\n",
      "Here, `factorial(5)` calls `factorial(4)`, which calls `factorial(3)`, and so on, until it reaches `factorial(0)` (the base case).\n",
      "\n",
      "### When Not to Use Recursion:\n",
      "- If the problem can be solved more efficiently with a loop (recursion can be slower and use more memory).\n",
      "- If the recursion goes too deep (it might cause a \"stack overflow\" error).\n",
      "\n",
      "Would you like another example or clarification? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1717cee-c9cc-4846-b597-50f44d6bacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools the LLM can use (JSON Schema format)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name, e.g., 'San Francisco, CA'\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"Temperature unit\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2989270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Madison, WI\"}]\n",
    "\n",
    "response = completion(\n",
    "    model=MODEL,\n",
    "    messages = messages,\n",
    "    tools = tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6301d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(content='```json\\n{\"name\": \"get_weather\", \"arguments\": {\"location\": \"Madison, WI\"}}\\n```', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None)\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fc0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"calculate\",\n",
    "                \"description\": \"Perform a mathematical calculation\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Math expression to evaluate, e.g., '2 + 2 * 3'\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_exchange_rate\",\n",
    "                \"description\": \"Get the exchange rate between two currencies\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"from_currency\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Source currency code, e.g., 'USD'\",\n",
    "                        },\n",
    "                        \"to_currency\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Target currency code, e.g., 'EUR'\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"from_currency\", \"to_currency\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7935b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated tool implementations\n",
    "def execute_tool(name: str, arguments: dict) -> str:\n",
    "    \"\"\"Execute a tool and return the result as a string.\"\"\"\n",
    "    if name == \"calculate\":\n",
    "        try:\n",
    "            # WARNING: eval is dangerous!\n",
    "            result = eval(arguments[\"expression\"])\n",
    "            return json.dumps({\"result\": result})\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "\n",
    "    elif name == \"get_exchange_rate\":\n",
    "        # Simulated exchange rates\n",
    "        rates = {\n",
    "            (\"USD\", \"EUR\"): 0.92,\n",
    "            (\"USD\", \"JPY\"): 149.50,\n",
    "            (\"EUR\", \"USD\"): 1.09,\n",
    "        }\n",
    "        key = (arguments[\"from_currency\"], arguments[\"to_currency\"])\n",
    "        rate = rates.get(key, 1.0)\n",
    "        return json.dumps(\n",
    "            {\n",
    "                \"from\": arguments[\"from_currency\"],\n",
    "                \"to\": arguments[\"to_currency\"],\n",
    "                \"rate\": rate,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return json.dumps({\"error\": \"Unknown tool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "438a9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Start the conversation\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I have 150 USD. How much is that in EUR? Then calculate what 15% tip would be on that EUR amount.\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0da2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: I have 150 USD. How much is that in EUR? Then calculate what 15% tip would be on that EUR amount.\n",
      "\n",
      "--- Agentic Loop Starting ---\n",
      "\n",
      "[Iteration 1]\n",
      "\n",
      "--- Agentic Loop Complete ---\n",
      "\n",
      "Final Answer: ```json\n",
      "{\"name\": \"get_exchange_rate\", \"arguments\": {\"from_currency\": \"USD\", \"to_currency\": \"EUR\"}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nUser: {messages[0]['content']}\")\n",
    "print(\"\\n--- Agentic Loop Starting ---\")\n",
    "\n",
    "# The agentic loop\n",
    "for iteration in range(1, 11):\n",
    "    print(f\"\\n[Iteration {iteration}]\")\n",
    "\n",
    "    response = completion(model=MODEL, messages=messages, tools=tools)\n",
    "    assistant_message = response.choices[0].message\n",
    "    messages.append(assistant_message.model_dump())\n",
    "\n",
    "    if not assistant_message.tool_calls:\n",
    "        print(\"\\n--- Agentic Loop Complete ---\")\n",
    "        print(f\"\\nFinal Answer: {assistant_message.content}\")\n",
    "        break\n",
    "\n",
    "    for tc in assistant_message.tool_calls:\n",
    "        args = json.loads(tc.function.arguments)\n",
    "        print(f\"  Tool call: {tc.function.name}({args})\")\n",
    "        result = execute_tool(tc.function.name, args)\n",
    "        print(f\"  Result: {result}\")\n",
    "        messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": result})\n",
    "else:\n",
    "    print(\"\\nWarning: Max iterations reached!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f68c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: List the Python files in the current directory and count them.\n",
      "\n",
      "Assistant: {\"bash\": {\"command\": \"ls -1 *.py | wc -l\"}}\n",
      "{\"bash\": {\"command\": \"ls -1 *.py\"}}\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"bash\",\n",
    "            \"description\": \"Run a bash command and return stdout/stderr\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"command\": {\"type\": \"string\", \"description\": \"The bash command to run\"}\n",
    "                },\n",
    "                \"required\": [\"command\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "import subprocess\n",
    "def run_bash(command: str) -> str:\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    return result.stdout + result.stderr or \"(no output)\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that can run bash commands. Be concise.\"},\n",
    "    {\"role\": \"user\", \"content\": \"List the Python files in the current directory and count them.\"},\n",
    "]\n",
    "\n",
    "print(f\"\\nUser: {messages[1]['content']}\")\n",
    "\n",
    "for _ in range(10):\n",
    "    response = completion(model=MODEL, messages=messages, tools=tools)\n",
    "    msg = response.choices[0].message\n",
    "    messages.append(msg.model_dump())\n",
    "\n",
    "    if not msg.tool_calls:\n",
    "        print(f\"\\nAssistant: {msg.content}\")\n",
    "        break\n",
    "\n",
    "    for tc in msg.tool_calls:\n",
    "        cmd = json.loads(tc.function.arguments)[\"command\"]\n",
    "        print(f\"\\n$ {cmd}\")\n",
    "        output = run_bash(cmd)\n",
    "        print(output)\n",
    "        messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bb4cc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: bash\n",
      "Here is the list of files and directories in the `venv` directory:\n",
      "\n",
      "- `bin`: A directory (likely contains executable scripts).\n",
      "- `include`: A directory (likely contains header files).\n",
      "- `lib`: A directory (likely contains library files).\n",
      "- `lib64`: A symbolic link pointing to `lib`.\n",
      "- `pyvenv.cfg`: A configuration file for the virtual environment.\n",
      "- `share`: A directory (likely contains shared data).Here is the list of files and directories in the `venv` directory:\n",
      "\n",
      "- `bin`: A directory (likely contains executable scripts).\n",
      "- `include`: A directory (likely contains header files).\n",
      "- `lib`: A directory (likely contains library files).\n",
      "- `lib64`: A symbolic link pointing to `lib`.\n",
      "- `pyvenv.cfg`: A configuration file for the virtual environment.\n",
      "- `share`: A directory (likely contains shared data).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from strands import Agent, tool\n",
    "from strands.models import ollama\n",
    "\n",
    "@tool\n",
    "def bash(cmd: str) -> str:\n",
    "    p = subprocess.run([\"bash\", \"-lc\", cmd], capture_output=True, text=True)\n",
    "    return f\"exit_code={p.returncode}\\nSTDOUT:\\n{p.stdout}\\nSTDERR:\\n{p.stderr}\"\n",
    "\n",
    "model = ollama.OllamaModel(\n",
    "    model_id=\"devstral-small-2:24b-cloud\",              # must match `ollama list`\n",
    "    host=\"http://localhost:11434\",       # default Ollama host\n",
    ")\n",
    "\n",
    "agent = Agent(model=model, tools=[bash])\n",
    "print(agent(\"Use bash to list files in the directory: venv.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43be39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
